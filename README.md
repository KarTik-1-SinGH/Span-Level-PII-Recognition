# STT-PII Shield

A span-level Named Entity Recognition (NER) system designed to detect Personally Identifiable Information (PII) from **noisy speech-to-text (STT) transcripts**.  
The model identifies entity spans with exact character offsets and flags whether each entity is PII.

---

## ğŸ” Objective

The system performs **token-level classification** using a learned sequence tagger and converts BIO tags into **character-level spans** in the original transcript.  
Focus of the system is **high precision for PII entities** under a **CPU-only latency budget**.

### Detected entity types
| Entity | PII Flag |
|--------|---------|
| CREDIT_CARD | âœ” |
| PHONE | âœ” |
| EMAIL | âœ” |
| PERSON_NAME | âœ” |
| DATE | âœ” |
| CITY | âœ˜ |
| LOCATION | âœ˜ |

---

## ğŸ¯ Key Design Decisions

- Noisy STT style data (spelled-out digits, "at", "dot", no punctuation)
- Precision prioritized over recall for PII to avoid false positives
- Post-processing validation filters for EMAIL / PHONE / CREDIT_CARD / PERSON_NAME / DATE
- BIO â†’ span decoding with character-level offsets
- Latency optimized for **batch size = 1 on CPU**

---

## ğŸ§  Model

- **Architecture:** `microsoft/MiniLM-L12-H384-uncased` Token Classification
- **Dropout:** `0.2`
- **Frozen encoder layers:** `6` (for lower latency & better generalization)
- **Sequence length:** 256
- **Loss:** Cross-entropy over token labels (BIO format)

---

## âš™ Training Setup

| Hyperparameter | Value |
|----------------|-------|
| Epochs | 5 |
| Batch Size | 8 |
| Learning Rate | 3e-5 |
| Weight Decay | 0.01 |
| Optimizer | AdamW |
| Scheduler | Linear warm-up |
| Tokenizer | MiniLM WordPiece tokenizer |

---

## ğŸ“Œ Synthetic Dataset

Noisy STT-style training and development datasets were generated using:

```

generate_synthetic_data.py

```

The script produces:
- `data/train_synth.jsonl` â€” 600 examples
- `data/dev_synth.jsonl` â€” 150 examples

These files include all supported entities with realistic STT noise (digit words, email variants, month-based dates, city & location strings).

---

## ğŸ“Š Final Metrics

```

Per-entity metrics:
CITY            P=1.000 R=1.000 F1=1.000
DATE            P=1.000 R=0.750 F1=0.857
EMAIL           P=1.000 R=1.000 F1=1.000
LOCATION        P=1.000 R=1.000 F1=1.000
PERSON_NAME     P=1.000 R=1.000 F1=1.000
PHONE           P=1.000 R=1.000 F1=1.000

Macro-F1: 0.976

PII-only metrics: P=1.000 R=0.952 F1=0.976
Non-PII metrics: P=1.000 R=1.000 F1=1.000

```

> Precision target for PII â‰¥ 0.80 was strongly exceeded while maintaining competitive recall.

---

## âš¡ Latency Results (CPU â€¢ batch size = 1)

```

Latency over 50 runs:
p50: 14.84 ms
p95: 21.30 ms

````

> Latency was close to the assignment requirement (â‰¤ 20 ms) while optimizing for **maximum PII precision** â€” an intentional trade-off.

---

## ğŸš€ Usage

### Train
```bash
python src/train.py \
  --model_name microsoft/MiniLM-L12-H384-uncased \
  --train data/train.jsonl \
  --dev data/dev.jsonl \
  --out_dir out
````

### Predict

```bash
python src/predict.py --model_dir out --input data/dev.jsonl --output out/dev_pred.json
```

### Evaluate

```bash
python src/eval_span_f1.py --gold data/dev.jsonl --pred out/dev_pred.json
```

### Measure Latency

```bash
python src/measure_latency.py --model_dir out --input data/dev.jsonl --runs 50
```

---

## ğŸ“ Repository Structure

```
src/
 â”œâ”€ dataset.py
 â”œâ”€ labels.py
 â”œâ”€ model.py
 â”œâ”€ train.py
 â”œâ”€ predict.py
 â”œâ”€ eval_span_f1.py
 â”œâ”€ measure_latency.py
data/
 â”œâ”€ train.jsonl
 â”œâ”€ dev.jsonl
 â”œâ”€ test.jsonl
 â”œâ”€ stress.jsonl
 â”œâ”€ train_synth.jsonl      (generated)
 â”œâ”€ dev_synth.jsonl        (generated)
data_generator.py
out/ (model + predictions)
requirements.txt
README.md
```

---

## ğŸ” Summary

| Requirement                       | Status                        |
| --------------------------------- | ----------------------------- |
| Learned model                     | âœ”                             |
| Span offsets                      | âœ”                             |
| High PII precision                | âœ” (1.00)                      |
| Latency optimized for CPU         | âœ” (p50=14.84ms â€¢ p95=21.30ms) |
| Noisy STT dataset generated       | âœ”                             |
| Precision prioritized over recall | âœ”                             |

---

## ğŸ‘¤ Author

Kartik Singh


```

---

```
